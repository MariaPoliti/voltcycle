{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.txt Opened\n",
      "1\n",
      "2\n",
      "executed\n"
     ]
    }
   ],
   "source": [
    "import file_read\n",
    "import baseline\n",
    "import calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from matplotlib import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import matplotlib.cbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cycle(data):\n",
    "    \"\"\"This function reads a segment of datafile (corresponding a cycle)\n",
    "    and generates a dataframe with columns 'Potential' and 'Current'\n",
    "\n",
    "    Parameters\n",
    "    __________\n",
    "    data: segment of data file\n",
    "\n",
    "    Returns\n",
    "    _______\n",
    "    A dataframe with potential and current columns  \n",
    "    \"\"\"     \n",
    "\n",
    "    current = []\n",
    "    potential = []\n",
    "    for i in data[3:]:\n",
    "        current.append(float(i.split(\"\\t\")[4]))\n",
    "        potential.append(float(i.split(\"\\t\")[3]))\n",
    "    zippedList = list(zip(potential, current))\n",
    "    df = pd.DataFrame(zippedList, columns = ['Potential' , 'Current'])\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file):\n",
    "    \"\"\"This function reads the raw data file, gets the scanrate and stepsize\n",
    "    and then reads the lines according to cycle number. Once it reads the data\n",
    "    for one cycle, it calls read_cycle function to denerate a dataframe. It \n",
    "    does the same thing for all the cycles and finally returns a dictionary,\n",
    "    the keys of which are the cycle numbers and the values are the \n",
    "    corresponding dataframes.\n",
    "\n",
    "    Parameters\n",
    "    __________\n",
    "    file: raw data file\n",
    "\n",
    "    Returns:\n",
    "    ________\n",
    "    dict_of_df: dictionary of dataframes with keys = cycle numbers and\n",
    "    values = dataframes for each cycle\n",
    "    n_cycle: number of cycles in the raw file  \n",
    "    \"\"\"   \n",
    "    dict_of_df = {} \n",
    "    h = 0\n",
    "    l = 0\n",
    "    n_cycle = 0\n",
    "    #a = []\n",
    "    with open(file, 'rt') as f:\n",
    "        print(file + ' Opened')\n",
    "        for line in f:\n",
    "            record = 0\n",
    "            if not (h and l):\n",
    "                if line.startswith('SCANRATE'):\n",
    "                    scan_rate = float(line.split()[2])\n",
    "                    h = 1\n",
    "                if line.startswith('STEPSIZE'):\n",
    "                    step_size = float(line.split()[2])\n",
    "                    l = 1\n",
    "            if line.startswith('CURVE'):\n",
    "                n_cycle += 1\n",
    "                if n_cycle > 1:\n",
    "                    number = n_cycle - 1\n",
    "                    df = read_cycle(a)\n",
    "                    key_name = 'cycle_' + str(number)\n",
    "                    #key_name = number\n",
    "                    dict_of_df[key_name] = copy.deepcopy(df)\n",
    "                a = []\n",
    "            if n_cycle:\n",
    "                a.append(line)\n",
    "    return dict_of_df, number\n",
    "\n",
    "\n",
    "#df = pd.DataFrame(list(dict1['df_1'].items()))\n",
    "#list1, list2 = list(dict1['df_1'].items())\n",
    "#list1, list2 = list(dict1.get('df_'+str(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_frame(dict_cycle, n):\n",
    "    \"\"\"Reads the dictionary of dataframes and returns dataframes for each cycle\n",
    "\n",
    "    Parameters\n",
    "    __________\n",
    "    dict_cycle: Dictionary of dataframes\n",
    "    n: cycle number\n",
    "\n",
    "    Returns:\n",
    "    _______\n",
    "    Dataframe correcponding to the cycle number \n",
    "    \"\"\"\n",
    "    list1, list2 = (list(dict_cycle.get('cycle_'+str(n)).items()))\n",
    "    zippedList = list(zip(list1[1], list2[1]))\n",
    "    data  = pd.DataFrame(zippedList, columns = ['Potential' , 'Current'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(dict, n):\n",
    "    \"\"\"For basic plotting of the cycle data\n",
    "  \n",
    "    Parameters\n",
    "    __________\n",
    "    dict: dictionary of dataframes for all the cycles\n",
    "    n: number of cycles\n",
    "\n",
    "    Saves the plot in a file called cycle.png \n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(n):\n",
    "        print(i+1)\n",
    "        df = data_frame(dict_cycle, i+1)\n",
    "        plt.plot(df.Potential, df.Current, label = \"Cycle{}\".format(i+1))\n",
    "        \n",
    "    \n",
    "    plt.xlabel('Voltage')\n",
    "    plt.ylabel('Current')\n",
    "    plt.legend()\n",
    "    plt.savefig('cycle.png')\n",
    "    print('executed')\n",
    "\n",
    "\n",
    "dict_cycle, n_cycle  = read_file('test.txt')\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "plot(dict_cycle, n_cycle)\n",
    "return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split forward and backward sweping data, to make it easier for processing.\n",
    "def split(vector):\n",
    "    \"\"\"\n",
    "    This function takes an array and splits it into two half.\n",
    "    \"\"\"\n",
    "    split = int(len(vector)/2)\n",
    "    end = int(len(vector))\n",
    "    vector1 = np.array(vector)[0:split]\n",
    "    vector2 = np.array(vector)[split:end]\n",
    "    return vector1, vector2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def critical_idx(x, y): ## Finds index where data set is no longer linear \n",
    "    \"\"\"\n",
    "    This function takes x and y values callculate the derrivative of x and y, and calculate moving average of 5 and 15 points.\n",
    "    Finds intercepts of different moving average curves and return the indexs of the first intercepts.\n",
    "    \"\"\"\n",
    "    k = np.diff(y)/(np.diff(x)) #calculated slops of x and y\n",
    "\n",
    "    ## Calculate moving average for 5 and 15 points.\n",
    "    ## This two arbitrary number can be tuned to get better fitting.\n",
    "    ave5 = []\n",
    "    ave15 = []\n",
    "    for i in range(len(x)-5):  # The reason to minus 5 is to prevent j from running out of index.\n",
    "        a = 0 \n",
    "        for j in range(0,5):\n",
    "            a = a + k[i+j]\n",
    "        ave5.append(round(a/5, 9)) # keeping 9 desimal points for more accuracy\n",
    "    ave5 = np.asarray(ave5)\n",
    "    for i in range(len(x)-15): \n",
    "        b = 0 \n",
    "        for j in range(0,15):\n",
    "            b = b + k[i+j]\n",
    "        ave15.append(round(b/15, 9))\n",
    "    ave15 = np.asarray(ave15)\n",
    "    ## Find intercepts of different moving average curves\n",
    "    idx = np.argwhere(np.diff(np.sign(ave15 - ave5[:len(ave15)])!= 0)).reshape(-1) #reshape into one row.\n",
    "    return int(idx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(vector):\n",
    "    \"\"\"\n",
    "    This function returns the mean values.\n",
    "    \"\"\"\n",
    "    a = 0\n",
    "    for i in vector:\n",
    "        a = a + i\n",
    "    return a/len(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_coeff(x, y):\n",
    "    \"\"\"\n",
    "    This function returns the inclination coeffecient and y axis interception coeffecient m and b. \n",
    "    \"\"\"\n",
    "    m = (y-mean(y)) / (x - mean(x))    \n",
    "    b = mean(y) - m * mean(x)\n",
    "    return m, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_fitted_line(m, b, x):\n",
    "    y_base = []\n",
    "    for i in x:\n",
    "        y = m * i + b\n",
    "        y_base.append(y)\n",
    "    return y_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_background(x, y):\n",
    "    idx = critical_idx(x, y) + 3 #this is also arbitrary number we can play with.\n",
    "    m, b = linear_coeff(x[(idx - int(0.5 * idx)) : (idx + int(0.5 * idx))], y[(idx - int(0.5 * idx)) : (idx + int(0.5 * idx))])\n",
    "    y_base = y_fitted_line(m, b, x)\n",
    "    return y_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    ## Read from Chowdhury's function to get x and y\n",
    "  ##### Really need to work on how to catch data from different way. We have to capture different cycles.\n",
    "    try:\n",
    "        x = pd.to_numeric(data[x_label]) \n",
    "        y = pd.to_numeric(data[y_label])\n",
    "        ## Split vectors\n",
    "        x1, x2 = split(x)\n",
    "        y1, y2 = split(y)\n",
    "        ## Finds linear background \t\n",
    "        y_base1 = linear_background(x1,y1)\n",
    "        y_base2 = linear_background(x2,y2)\n",
    "        #cathodic peak current and potential\n",
    "        max_pos = y2.argmax()\n",
    "        max_pot = x2[max_pos]\n",
    "        max_cur = y2[max_pos] - y_base2[max_pos]\n",
    "        #Anodic peak current and potential\n",
    "        min_pos = y1.argmin()\n",
    "        min_pot = x1[min_pos]\n",
    "        min_cur = y1[min_pos] - y_base1[min_pos]\n",
    "        f\"For this CV data, the 'Ipc' is {max_cur}, Vpc is {max_pot}, Ipa is {min_cur}, Vpa is {min_pot}\"\n",
    "    except:\n",
    "        print('Data set could not be processed')\n",
    "    \n",
    "    ## Plot all data \n",
    "    plt.plot(x1, y1, 'dodgerblue',linewidth=1) ##darkgrey\n",
    "    plt.plot(x2, y2, 'dodgerblue', linewidth=1) ##dodgerblue  \n",
    "    plt.plot(x1, y_base1, color = \"orangered\", linestyle=':',linewidth=2) \n",
    "    plt.plot(x2, y_base2, color = \"orangered\", linestyle=':',linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peak stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolation(data_x, data_y):\n",
    "   \"\"\"interpolation(dataframe['x column'], dataframe['y column'])\n",
    "   This function returns a list of the fitted values of the peals in the dataset.\n",
    "   It calls the peak_detection function and type casts the outputs to numpy ndarrays\n",
    "   (as that is what the peakutils.interpolation function takes in).\n",
    "   The function also typecasts the x and y value columns to numpy ndarrays.\n",
    "   The function then uses the peakutils.interpolation function to enhance the resolution of the peak values.\n",
    "   This gives more precise numbers. The function returns a list.\"\"\"\n",
    "\n",
    "   x = np.array(data_x)\n",
    "   y = np.array(data_y)\n",
    "\n",
    "   index = peak_detection(data_y)[0]\n",
    "   index = np.asarray(index)\n",
    "\n",
    "   smooth_index = []\n",
    "   smooth = peakutils.interpolate(x, y, ind=index)\n",
    "   smooth_index.append(list(smooth))\n",
    "\n",
    "   return smooth_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import peakutils\n",
    "def peak_detection(data_y):\n",
    "   \"\"\" peak_detection(dataframe['y column'])\n",
    "   This function returns a list of the indecies of the y values of the peaks detected in the dataset.\n",
    "   The function takes an input of the column containing the y variables in the dataframe.\n",
    "   This column is then split into two arrays, one of the positive and one of the negative values.\n",
    "   This is because cyclic voltammetry delivers negative peaks however the peakutils function work better with positive peaks.\n",
    "   The absolute values of each of these vectors are then imported into the peakutils.indexes\n",
    "   function to determine the significant peak(s) for each array. The value(s) are then saved as a list.\"\"\"\n",
    "\n",
    "   index_list = []\n",
    "\n",
    "   y1, y2 = split_column(data_y)\n",
    "\n",
    "   peak_top = peakutils.indexes(abs(y1), thres=0.5, min_dist=0.001)\n",
    "   peak_bottom = peakutils.indexes(abs(y2), thres=0.5, min_dist=0.001)\n",
    "   index_list.append([peak_top[0], peak_bottom[0]])\n",
    "\n",
    "   return index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_column(column):\n",
    "\n",
    "   first_half = int(len(column)/2)\n",
    "   second_half = int(len(column))\n",
    "   col_array = np.array(column)\n",
    "   col1 = col_array[0:first_half]\n",
    "   col2 = col_array[(first_half+1):second_half]\n",
    "   return col1, col2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_potentials(data, index, potential_column_name):\n",
    "    \"\"\"Outputs potentials of given peaks in cyclic voltammetry data.\n",
    "\n",
    "       Parameters\n",
    "       ----------\n",
    "       data : Must be in the form of a pandas DataFrame\n",
    "\n",
    "       index : integer(s) in the form of a list or numpy array\n",
    "\n",
    "       potential_column_name : the name of the column of the DataFrame\n",
    "         which contains potentials from cyclic voltammogram. If a string,\n",
    "         must be input with single or double quotation marks\n",
    "\n",
    "       Returns\n",
    "       -------\n",
    "       Result : numpy array of potentials at peaks.\"\"\"\n",
    "    series = data.iloc[index][potential_column_name]\n",
    "    potentials_array = (series).values\n",
    "    return potentials_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_potential(data, index, potential_column_name):\n",
    "    \"\"\"Outputs the difference in potentials between anodic and cathodic peaks\n",
    "       in cyclic voltammetry data.\n",
    "\n",
    "       Parameters\n",
    "       ----------\n",
    "       data : Must be in the form of a pandas DataFrame\n",
    "\n",
    "       index : integer(s) in the form of a list or numpy array\n",
    "\n",
    "       potential_column_name : the name of the column of the DataFrame\n",
    "         which contains potentials from cyclic voltammogram. If a string,\n",
    "         must be input with single or double quotation marks.\n",
    "\n",
    "       Returns\n",
    "       -------\n",
    "       Results : difference in the form of a floating point number. \"\"\"\n",
    "    del_potential = (\n",
    "        peak_potentials(data, index, potential_column_name)[1] -\n",
    "        peak_potentials(data, index, potential_column_name)[0]\n",
    "    )\n",
    "    return del_potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_wave_potential(data, index, potential_column_name):\n",
    "    \"\"\"Outputs the half wave potential(redox potential) from cyclic\n",
    "       voltammetry data.\n",
    "\n",
    "       Parameters\n",
    "       ----------\n",
    "       data : Must be in the form of a pandas DataFrame\n",
    "\n",
    "       index : integer(s) in the form of a list or numpy array\n",
    "\n",
    "       potential_column_name : the name of the column of the DataFrame\n",
    "         which contains potentials from cyclic voltammogram. If a string,\n",
    "         must be input with single or double quotation marks\n",
    "\n",
    "       Returns\n",
    "       -------\n",
    "       Results : the half wave potential in the form of a\n",
    "         floating point number.\"\"\"\n",
    "    half_wave_potential = (del_potential(data, index, potential_column_name))/2\n",
    "    return half_wave_potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_currents(data, index, current_column_name):\n",
    "    \"\"\"Outputs currents of given peaks in cyclic voltammetry data.\n",
    "\n",
    "       Parameters\n",
    "       ----------\n",
    "       data : Must be in the form of a pandas DataFrame\n",
    "\n",
    "       index : integer(s) in the form of a list or numpy array\n",
    "\n",
    "       current_column_name : the name of the column of the DataFrame\n",
    "         which contains potentials from cyclic voltammogram. If a string,\n",
    "         must be input with single or double quotation marks\n",
    "\n",
    "       Returns\n",
    "       -------\n",
    "       Result : numpy array of currents at peaks\"\"\"\n",
    "    series = data.iloc[index][current_column_name]\n",
    "    currents_array = (series).values\n",
    "    return currents_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
